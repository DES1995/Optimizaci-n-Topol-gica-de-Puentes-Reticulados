# OptimizaciÃ³n TopolÃ³gica de Puentes Reticulados Asistida por Aprendizaje AutomÃ¡tico y Algoritmos de OptimizaciÃ³n Bioinspirada

## ğŸ¯ Objetivo
Este proyecto busca desarrollar un pipeline que combine tÃ©cnicas de **optimizaciÃ³n topolÃ³gica** con modelos de **aprendizaje automÃ¡tico** y **algoritmos de optimizaciÃ³n bioinspirada** (GA, PSO, HHO, etc.) para obtener **configuraciones eficientes de puentes reticulados**, minimizando el peso estructural y garantizando su desempeÃ±o bajo criterios normativos.

## ğŸ‘¥ Autor
- Ing. Deiby Estacio SÃ¡nchez  
  - Email: deiby.estacio.s@uni.pe  
  - GitHub: [DEIBY_1995](https://github.com/DEIBY-1995)

---

## ğŸ“Š Dataset
Este proyecto combina datasets pÃºblicos y generados para entrenar y validar modelos de optimizaciÃ³n topolÃ³gica en puentes reticulados:

- **CEM Dataset** â€“ TopologÃ­as estructurales generadas mediante el *Combinatorial Equilibrium Modelling (CEM)*.  
  Fuente: [GitHub â€“ arpastrana/cem_dataset](https://github.com/arpastrana/cem_dataset)  

- **2D Analysis of Frame and Truss** â€“ Dataset de anÃ¡lisis de pÃ³rticos y cerchas en 2D.  
  Fuente: [Kaggle â€“ 2D Analysis of Frame and Truss](https://www.kaggle.com/datasets/sarankanna/2d-analysis-of-frame-and-truss)  

- **Zenodo Multi-material Optimization Dataset** â€“ Dataset asociado a experimentos de optimizaciÃ³n estructural con mÃºltiples materiales.  
  Fuente: [Zenodo â€“ DOI:10.5281/zenodo.14773973](https://zenodo.org/records/14773973)  

### ğŸ”§ Uso de datasets
- Los datasets serÃ¡n **preprocesados** para extraer variables clave:  
  - Nodos, barras y conectividad topolÃ³gica.  
  - Propiedades mecÃ¡nicas (mÃ³dulo E, cargas, lÃ­mites de esbeltez).  
  - Respuesta estructural (desplazamientos, esfuerzos, masa normalizada).  
- Se generarÃ¡ un dataset integrado en `data/processed/bridges_truss.csv` que servirÃ¡ como entrada a los modelos de ML y a los algoritmos de optimizaciÃ³n bioinspirada.

---

## ğŸ“‚ Estructura del repositorio
```
data/
 â”œâ”€â”€ raw/                       # Datasets originales descargados (CEM, Kaggle, Zenodo)
 â”œâ”€â”€ processed/                 # Dataset limpio e integrado para ML

notebooks/
 â”œâ”€â”€ EDA_basico.ipynb           # AnÃ¡lisis exploratorio inicial (EDA, riesgos)
 â””â”€â”€ Baseline_basico.ipynb      # Entrenamiento de baselines (Dummy + kNN)

src/
 â”œâ”€â”€ ingesta.py                 # Script de ingesta (raw â†’ staging)
 â”œâ”€â”€ preprocesamiento.py        # Limpieza, integraciÃ³n y feature engineering
 â””â”€â”€ modelo_baseline.py         # Modelos baseline (Dummy, kNN, mÃ©tricas iniciales)

logs/                           # Archivos de logging y mÃ©tricas
slides/                         # Presentaciones de resultados
README.md                       # DocumentaciÃ³n principal
pyproject.toml                  # ConfiguraciÃ³n del proyecto (Poetry)
poetry.lock / requirements.txt  # Dependencias del proyecto
.gitignore                      # Exclusiones de Git
```

---

## âš™ï¸ Requisitos
Instala dependencias con:
```bash
pip install -r requirements.txt
```
o, si usas Poetry:
```bash
poetry install
```

---

## â–¶ï¸ CÃ³mo correr el pipeline
1. Ingesta y preprocesamiento de datos:
```bash
python src/ingesta.py
python src/preprocesamiento.py
```

2. Entrenamiento baseline:
```bash
python src/modelo_baseline.py
```

Esto genera:
- MÃ©tricas iniciales en `logs/`  
- GrÃ¡ficos comparativos en `results/`  
- Dataset limpio en `data/processed/`

---

## ğŸ“ˆ Resultados esperados (mÃ­nimos)
- EstadÃ­sticas descriptivas y distribuciones de variables clave (EDA).  
- IdentificaciÃ³n de riesgos: **leakage, desbalance, drift**.  
- Modelos baseline simples (Dummy, kNN).  
- MÃ©tricas iniciales coherentes con el problema (F1/ROC-AUC para clasificaciÃ³n, MAE/RMSE para regresiÃ³n).  
- GrÃ¡ficos y tablas de desempeÃ±o inicial.  

---

## ğŸ§­ PrÃ³ximos pasos
- Sustituir datasets de prueba por instancias FEM/optimizaciÃ³n topolÃ³gica generadas.  
- Probar algoritmos bioinspirados (GA, PSO, HHO) para exploraciÃ³n del espacio de soluciones.  
- Integrar modelos de **Graph Neural Networks (GNN)** para representar mejor la conectividad estructural.  
- Optimizar pipeline para escalabilidad y eficiencia computacional.
